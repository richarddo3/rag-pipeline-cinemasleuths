from rag_pipeline.ingest import load_csv_documents, chunk_documents
from rag_pipeline.embeddings import embed_texts
from rag_pipeline.vector_store import build_faiss_index
from rag_pipeline.retriever import retrieve

df.to_csv("data/etl_cleaned_dataset.csv", index=False)

docs = load_csv_documents("data/etl_cleaned_dataset.csv")
chunks = chunk_documents(docs)

texts = [c["text"] for c in chunks]
embs = embed_texts(texts)

index = build_faiss_index(embs)

retrieve("Your question here", chunks, index, k=3)

